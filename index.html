<!DOCTYPE html>
<html lang="zh-Hant">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>ä¸­æ–‡èªéŸ³è¾¨è­˜ + æ³¢å½¢å‹•ç•«</title>
<style>
body { font-family: 'Segoe UI', sans-serif; text-align: center; background: #0b1220; color: white; margin:0; padding-top:60px; }
button { background: #6366f1; color:white; border:none; padding:12px 25px; border-radius:8px; font-size:18px; cursor:pointer; }
#text { margin-top:20px; font-size:22px; min-height:40px; }
#indicator { width:20px; height:20px; margin:20px auto; border-radius:50%; background:gray; box-shadow:0 0 10px gray; transition: background 0.3s; }
canvas { display:block; margin:20px auto; background:#031124; border-radius:8px; }
.recording { background:#ef4444 !important; box-shadow:0 0 15px #ef4444; }
</style>
</head>
<body>
<h2>ğŸ¤ ä¸­æ–‡èªéŸ³è¾¨è­˜ + æ³¢å½¢å‹•ç•« + è‡ªå‹•æœ—è®€</h2>
<button id="startBtn">é–‹å§‹</button>
<div id="indicator"></div>
<canvas id="waveCanvas" width="400" height="80"></canvas>
<div id="text"></div>
<audio id="beep" src="https://actions.google.com/sounds/v1/alarms/beep_short.ogg" preload="auto"></audio>

<script>
const startBtn = document.getElementById('startBtn');
const textDiv = document.getElementById('text');
const beep = document.getElementById('beep');
const indicator = document.getElementById('indicator');
const canvas = document.getElementById('waveCanvas');
const ctx = canvas.getContext('2d');

let silenceTimer = null;
let audioCtx, analyser, dataArray, source;

// Web Speech API
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();
recognition.lang = 'zh-TW';
recognition.continuous = false;
recognition.interimResults = false;

// ğŸ”¹ åˆå§‹åŒ–èªéŸ³ç³»çµ± (iOS å¿…é ˆä½¿ç”¨è€…äº’å‹•)
async function initVoice() {
  return new Promise(resolve=>{
    const u = new SpeechSynthesisUtterance('');
    u.volume = 0;
    u.onend = resolve;
    speechSynthesis.speak(u);
  });
}

// ğŸ”¹ é–‹å§‹éŒ„éŸ³ + æ³¢å½¢
async function startRecording() {
  indicator.classList.add('recording');
  beep.play();
  beep.onended = async () => {
    indicator.classList.add('recording');

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio:true });
      audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      source = audioCtx.createMediaStreamSource(stream);
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      dataArray = new Uint8Array(analyser.frequencyBinCount);

      drawWave(); // é–‹å§‹å‹•ç•«
      recognition.start();

      // 10 ç§’ç„¡è²ç›£æ§
      silenceTimer = setTimeout(()=>resetRecording(),10000);
    } catch(err) {
      console.error('éº¥å…‹é¢¨å–å¾—å¤±æ•—', err);
      indicator.classList.remove('recording');
    }
  };
}

// ğŸ”¹ æ³¢å½¢å‹•ç•«
function drawWave() {
  if(!analyser) return;
  requestAnimationFrame(drawWave);
  analyser.getByteTimeDomainData(dataArray);
  ctx.fillStyle = '#031124';
  ctx.fillRect(0,0,canvas.width,canvas.height);
  ctx.lineWidth = 2;
  ctx.strokeStyle = '#4f46e5';
  ctx.beginPath();
  const sliceWidth = canvas.width / dataArray.length;
  let x = 0;
  for(let i=0;i<dataArray.length;i++){
    const v = dataArray[i]/128.0;
    const y = v * canvas.height/2;
    if(i===0) ctx.moveTo(x,y);
    else ctx.lineTo(x,y);
    x += sliceWidth;
  }
  ctx.lineTo(canvas.width, canvas.height/2);
  ctx.stroke();

  // ç´…é»åŒæ­¥é–ƒçˆ
  const avg = dataArray.reduce((a,b)=>a+b,0)/dataArray.length;
  const brightness = Math.min(1, avg/128);
  indicator.style.background = `rgba(239,68,68,${0.3+0.7*brightness})`;
}

// ğŸ”¹ é‡ç½®éŒ„éŸ³
function resetRecording() {
  console.log('10 ç§’ç„¡è²ï¼Œè‡ªå‹•é‡ç½®éŒ„éŸ³');
  if(recognition) recognition.abort();
  if(audioCtx) audioCtx.close();
  indicator.classList.remove('recording');
  ctx.clearRect(0,0,canvas.width,canvas.height);
  startRecording();
}

// ğŸ”¹ èªéŸ³è¾¨è­˜äº‹ä»¶
recognition.onresult = e => {
  if(silenceTimer){ clearTimeout(silenceTimer); silenceTimer=null; }
  const text = e.results[0][0].transcript;
  textDiv.textContent = 'è¾¨è­˜çµæœï¼š'+text;
  indicator.classList.remove('recording');

  // èªéŸ³æœ—è®€
  const utter = new SpeechSynthesisUtterance(text);
  utter.lang = 'zh-TW';
  const voices = speechSynthesis.getVoices();
  const zhVoice = voices.find(v=>v.lang.startsWith('zh')||v.name.includes('Mei')||v.name.includes('Ting'));
  if(zhVoice) utter.voice = zhVoice;
  speechSynthesis.cancel();
  speechSynthesis.speak(utter);
  utter.onend = ()=>setTimeout(startRecording,1000);
};

recognition.onerror = e => {
  console.log('è¾¨è­˜éŒ¯èª¤ï¼š', e.error);
  if(silenceTimer){ clearTimeout(silenceTimer); silenceTimer=null; }
  indicator.classList.remove('recording');
  setTimeout(startRecording,1000);
};

recognition.onend = () => {
  if(silenceTimer){
    clearTimeout(silenceTimer);
    silenceTimer=null;
    resetRecording();
  }
};

// ğŸ”¹ ä½¿ç”¨è€…é»æ“Šå•Ÿå‹•
startBtn.onclick = async () => {
  startBtn.disabled = true;
  startBtn.textContent = 'åˆå§‹åŒ–ä¸­...';
  await initVoice(); // å–šé†’èªéŸ³åˆæˆ
  startBtn.textContent = 'é‹ä½œä¸­...';
  startRecording();
};
</script>
</body>
</html>
